{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# import zipfile\n",
    "# import altair as alt\n",
    "# from sklearn import set_config\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.compose import make_column_transformer, make_column_selector\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import fbeta_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fc79c",
   "metadata": {},
   "source": [
    "## Title : Abalone Age Prediction based on Physical Measurements and Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ef433",
   "metadata": {},
   "source": [
    "## Summary - 1:\n",
    "\n",
    "In this project, we aimed to build a regression model using the k-Nearest Neighbours (k-NN) algorithm to predict the age of an abalone using its physical characteristics and sex. Since determining abalone age traditionally requires cutting the shell and counting rings (a destructive and time-consuming process), machine learning methods offer a non-destructive alternative for estimating age from easily measurable features. Age in this dataset is represented as Rings + 1.5, where each ring corresponds roughly to one year of growth and the additional 1.5 accounts for early development. For example, an abalone with 10 rings would be approximately 11.5 years old.\n",
    "\n",
    "Our k-NN Regressor (with $k=5$) produced an RMSE of approximately 2.2 rings on the test set, meaning the model’s predictions deviate from the true age by about 2 rings on average. The scatter plot of actual versus predicted values shows a generally increasing trend but with noticeable spread, especially among older abalones. This indicates that while k-NN captures broad growth patterns, predicting exact age remains challenging due to natural biological variability and overlapping physical features. Nevertheless, the model produces reasonable baseline performance and demonstrates that physical measurements contain meaningful information about abalone age. Further improvement could be achieved by tuning $k$ or exploring more complex models.\n",
    "\n",
    "Understanding the age of an abalone is important for marine biology research, sustainable fisheries management, and conservation, but the traditional method of aging, cutting the shell and counting internal rings, is destructive and difficult to apply at scale. A predictive model offers an alternative, which is useful for studying wild populations without harming them. However, its accuracy is limited by natural biological variability and nonlinear growth patterns, especially in older abalones. This means that while machine learning can support broad age estimation and population assessments, it may still fall short in situations where precise age measurements are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89617e",
   "metadata": {},
   "source": [
    "## Introduction - 2\n",
    "\n",
    "#### 2.1 Project Goal:\n",
    "Understand if physical features and sex can accurately predict the age of an abalone.\n",
    "\n",
    "#### 2.2 Background:\n",
    "Abalones are a type of marine mollusk widely harvested for food and shell products. Understanding their age is important for marine biology research, sustainable fisheries management, and conservation efforts. However, determining the age of an abalone is not straightforward. The most accurate method requires cutting the shell and counting the number of rings inside under a microscope, which is an approach that is destructive, labor-intensive, and not feasible at scale for monitoring wild populations [1].\n",
    "\n",
    "The Abalone dataset from the UCI Machine Learning Repository provides measurements of physical characteristics of abalone [2]. These features include:\n",
    "- Categorical: Sex (M, F, I)\n",
    "- Continuous physical measurements: Length, Diameter, Height, Whole weight, Shucked weight, Viscera weight, Shell weight\n",
    "such as shell length, diameter, height, whole weight, shucked weight, viscera weight, and shell weight.\n",
    "\n",
    "The dataset contains 4,177 observations and 8 predictor variables, representing a reasonably large sample for training and evaluating regression models. The measurements reflect biological growth patterns, making them strong candidates for predicting age. In addition, these variables are non-destructive measurements that can be collected easily and consistently. Since abalone age is strongly related to its size and mass, this dataset provides an opportunity to use machine learning to predict an abalone's age from its measurable physical features.\n",
    "\n",
    "Age in this dataset is recorded using the variable Rings, where Age = Rings + 1.5 years, reflecting the biological growth process of shell formation. Because Rings is a numeric, continuous output, predicting age is naturally formulated as a regression problem. Using measurable physical features to estimate age has the potential to provide a non-destructive, scalable tool for resource management and marine science applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4c726",
   "metadata": {},
   "source": [
    "## Methods - 3\n",
    "\n",
    "#### 3.1 Model Selection:\n",
    "\n",
    "k-Nearest Neighbours (k-NN) Regressor is our chosen model to predict the age of an abalone from it's physical characteristics and sex.\n",
    "\n",
    "This model estimates the age of a new abalone by finding the k most similar abalones in the training set, where similarity is measured using Euclidean distance in the standardized feature space and averaging their observed ring counts. \n",
    "\n",
    "We selected k-NN because it is a simple, easily interpretable, and non-parametric model that does not assume linear relationships between predictors and age. Because abalone growth patterns are expected to be non-linear, with shell dimensions increasing quickly when young and more slowly with age, a flexible model such as k-NN is well suited to capture these unknown relationships between physical characteristics, sex, and age [2].\n",
    "\n",
    "#### 3.2 Preprocessing Steps:\n",
    "\n",
    "Prior to model fitting, all numeric features were standardized with Standard Scaler to ensure that measurements on different scales contributed equally to the distance calculations. One Hot Encoding is performed on the Sex categorical feature.\n",
    "\n",
    "Hyperparameter tuning for k will be performed in future analysis for simplicity, as noted in the Milestone 1 project instructions as well. \n",
    "\n",
    "Scoring of the model will be based on Root Mean Squared Error (RMSE), since the target variable (Rings) is a continous variable. RMSE also penalizes large errors more heavily, which is desirable for age estimations as predicting an abalone to be far older or younger than it truly is is more problematic than small deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61475add-ad84-4b05-ab07-02bc34dd4d45",
   "metadata": {},
   "source": [
    "## Results - 4:\n",
    "\n",
    "#### 4.1 Exploratory Data Analysis\n",
    "Figure 1 summarizes how each physical measurement relates to the number of rings, which serves as a proxy for abalone age. In general, positive associations are observed across most predictors, indicating that larger and heavier abalones tend to have more rings. The observed patterns are nonlinear, with growth appearing faster in younger abalones and gradually slowing for older ones. This widening spread suggests that abalones with similar sizes can still vary considerably in age. Weight-based variables show particularly strong correlations with age, while height appears to be the least informative due to its very narrow range.\n",
    "\n",
    "Across all measurements, the three sex categories overlap substantially, indicating that sex alone does not form clear separations in age patterns. Because of this, sex is unlikely to serve as a strong individual predictor at this stage, although it is still included as a categorical feature for completeness.\n",
    "\n",
    "#### 4.2 Model Performance\n",
    "To evaluate whether physical characteristics can predict age, we trained a k-Nearest Neighbours regression model (k = 5) using scaled predictors. Figure 2 shows the relationship between actual and predicted ring counts on the test set. The dashed line represents perfect prediction. While the model captures the general increasing trend, there is considerable spread, especially for older abalones. This indicates that predictions become less reliable as age increases, which is consistent with the biological variability seen in the EDA.\n",
    "\n",
    "Model accuracy is summarized using RMSE, with a train RMSE of 1.86 and a test RMSE of 2.29. Given that the age in years is calculated as Rings + 1.5, an RMSE of around 2.3 rings implies that the model typically have an inaccuracy by about two years. This level of accuracy is reasonable for a simple, non-parametric model and suggests that physical features provide useful but imperfect information about age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e33b6e",
   "metadata": {},
   "source": [
    "## Discussion - 5:\n",
    "\n",
    "The EDA supports the idea that abalone age is broadly reflected in its size and weight, though with substantial natural variability. The nonlinear shape in the plots suggests that growth is not constant across life stages, which aligns with biological expectations. This makes it harder for simple linear relationships to fully capture the underlying patterns.\n",
    "\n",
    "The kNN model achieved a test RMSE of about 2.29 rings, meaning it usually predicts age within two rings or roughly two years of the true value. For younger abalones, predictions appear more accurate, while error increases for older individuals. This is consistent with the widening spread in the EDA and reflects how size becomes a weaker indicator of age later in life. Overall, the model shows that non-destructive measurements can give a fairly good approximation of age, although they cannot replace more precise biological methods.\n",
    "\n",
    "From a fisheries or conservation perspective, a model like this is valuable because it allows age estimation without harming the animal. Being able to reasonably estimate age from external measurements supports sustainable management, population monitoring, and ecological research. However, the two-year prediction error may be too large for applications requiring fine distinctions between similar-aged cohorts. \n",
    "\n",
    "In terms of assumptions and limitations, first, the model assumes that the relationships observed in the dataset generalize to real-world populations. In practice, growth can vary significantly across habitats, seasons, and food availability, which may reduce the model's accuracy outside the UCI dataset. We also assume that measurement error is small, but in reality, weight and size measurements may be less precise, potentially increasing prediction error.\n",
    "\n",
    "Another limitation concerns the predictors themselves. Many of the weight-based features are highly correlated, and while kNN can handle this structure, it also means that small measurement differences may disproportionately influence distance calculations. Additionally, height has limited variation and contributes minimally to prediction. Sex was included through onehot encoding, but since all three groups overlap heavily, it does not meaningfully improve the model at this stage.\n",
    "\n",
    "Finally, kNN does not extrapolate beyond observed examples, which makes it less reliable for rare or extreme cases. Its performance also depends heavily on the choice of k and the density of nearby data points, which may not always reflect the underlying biological complexity of abalone growth [3][4]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdd4c2",
   "metadata": {},
   "source": [
    "## Importing Dataset \n",
    "\n",
    "#### Steps \n",
    "1. Prepare data validation Schema using Pandera\n",
    "2. Load Data via URL \n",
    "3. Apply the Pandera Schema to validate the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234613a",
   "metadata": {},
   "source": [
    "##### Setting up Data Checking Schema\n",
    "\n",
    "Data Type of choice is selected from the original dataset source.\n",
    "\n",
    "We will use Pandera to check the followings: \n",
    "\n",
    "    1. Correct data file format\n",
    "\n",
    "    2. Correct column names\n",
    "\n",
    "    3. No empty observations\n",
    "\n",
    "    4. Missingness not beyond expected threshold\n",
    "\n",
    "    5. Correct data types in each column\n",
    "\n",
    "    6. No duplicate observations\n",
    "\n",
    "    7. No outlier or anomalous values\n",
    "\n",
    "    8. Correct category levels (i.e., no string mismatches or single values)\n",
    "\n",
    "We will use Deepcheck to check the followings: \n",
    "\n",
    "    9. Target/response variable follows expected distribution\n",
    "\n",
    "    10. No anomalous correlations between target/response variable and features/explanatory variables\n",
    "    \n",
    "    11. No anomalous correlations between features/explanatory variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4baecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import Column, Check, DataFrameSchema\n",
    "\n",
    "# Allowed categories for Sex\n",
    "SEX_CATEGORIES = [\"M\", \"F\", \"I\"]\n",
    "\n",
    "abalone_schema = DataFrameSchema(\n",
    "    {\n",
    "        \"Sex\": Column(\n",
    "            str,\n",
    "            Check.isin(SEX_CATEGORIES),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Length\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Diameter\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Height\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Whole_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Shucked_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Viscera_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Shell_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Rings\": Column(\n",
    "            int,\n",
    "            Check.between(1, 30),\n",
    "            nullable=False\n",
    "        )\n",
    "    },\n",
    "    checks=[\n",
    "        Check(lambda df: ~df.duplicated().any(), error=\"Duplicate rows found.\"),\n",
    "        Check(lambda df: ~(df.isna().all(axis=1)).any(), error=\"Empty rows found.\"),\n",
    "        Check(lambda df: (df.isna().mean() <= 0.05).all(),\n",
    "              error=\"Missingness exceeds 5% threshold.\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f424bdc",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac361e10-ddcf-4348-bdbd-8a56c917c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "\n",
    "column_names = [\n",
    "    \"Sex\", \"Length\", \"Diameter\", \"Height\",\n",
    "    \"Whole_weight\", \"Shucked_weight\",\n",
    "    \"Viscera_weight\", \"Shell_weight\", \"Rings\"\n",
    "]\n",
    "\n",
    "#This ensures our data is freshly loaded everytime :) \n",
    "#Creating a function here for the loading process: \n",
    "\n",
    "def load_and_validate_abalone() -> pd.DataFrame:\n",
    "    #1) Loading data \n",
    "    abalone_raw = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "    #2) validation with pandera\n",
    "    abalone_validated = abalone_schema.validate(abalone_raw, lazy=True)\n",
    "\n",
    "    return abalone_validated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10edb4",
   "metadata": {},
   "source": [
    "#### Validation with Pandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54164922",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = load_and_validate_abalone()\n",
    "\n",
    "#Saving the validated dataset\n",
    "abalone.to_csv(\"data/abalone_validated.csv\", index=False)\n",
    "\n",
    "# Peeking the dataframe\n",
    "abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527329d1",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "We will be perform a pairwise plot below to assess feature correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6e911-5142-41d0-b35e-f8e53b224fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "# Excluding column: Sex for cleaner display of graphs\n",
    "new_column_names = [\"Length\", \"Diameter\", \"Height\",\n",
    "    \"Whole_weight\", \"Shucked_weight\",\n",
    "    \"Viscera_weight\", \"Shell_weight\", \"Rings\"\n",
    "]\n",
    "\n",
    "# Plot all variables against one another for EDA\n",
    "chart = alt.Chart(abalone,width=150, height=100).mark_point().encode(\n",
    "    alt.X(alt.repeat('row'), type='quantitative'),\n",
    "    alt.Y(alt.repeat('column'), type='quantitative'),\n",
    "    color=alt.Color(\"Sex:N\", title=\"Abalone Sex\")\n",
    ").repeat(column = new_column_names, row = new_column_names\n",
    ").properties(title = \"Scatterplot matrix of abalone physical features and rings\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a83f6-2742-4634-ad4a-2d78e4a17425",
   "metadata": {},
   "source": [
    "Figure 1: Comparison of the relationships between abalone physical measurements and age (Rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1008ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. One-hot encode the Sex categorical variable\n",
    "# get_dummies() converts categories (M, F, I) -> columns Sex_F and Sex_M\n",
    "# drop_first=True avoids creating redundant dummy columns\n",
    "\n",
    "abalone_converted = pd.get_dummies(abalone, columns=[\"Sex\"], drop_first=True)\n",
    "\n",
    "# 2. Split predictors (X) and target variable (y)\n",
    "# \"Rings\" is the target we want to predict (continuous -> regression)\n",
    "\n",
    "X = abalone_converted.drop(\"Rings\", axis=1)\n",
    "y = abalone_converted[\"Rings\"]\n",
    "abalone_converted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ada80d-5a4f-4293-81ce-0ab3450b44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train-test split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ed45a",
   "metadata": {},
   "source": [
    "#### Validations with Deepcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c5f20-8016-4c08-87ba-af826765a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate training data for anomalous correlations between target/response variable \n",
    "# and features/explanatory variables, \n",
    "# as well as anomalous correlations between features/explanatory variables\n",
    "# Do these on training data as part of EDA\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureFeatureCorrelation, MultivariateDrift, LabelDrift\n",
    "from deepchecks.tabular import Dataset\n",
    "\n",
    "# Combine X_train and y_train to form training dataset\n",
    "abalone_train = X_train.copy()\n",
    "abalone_train[\"Rings\"] = y_train\n",
    "\n",
    "\n",
    "# Setting up Dataset object for Deepcheck\n",
    "abalone_train_ds = Dataset(\n",
    "    abalone_train.drop(columns=[\"Sex_I\", \"Sex_M\"]), \n",
    "    label=\"Rings\",\n",
    "    cat_features=[]\n",
    ")\n",
    "\n",
    "# 1. Feature–Label Correlation Check\n",
    "#    Ensures no single feature is too predictive of the target.\n",
    "#    PPS (predictive power score) must remain < 0.9.\n",
    "check_feat_lab_corr = FeatureLabelCorrelation().add_condition_feature_pps_less_than(0.9)\n",
    "check_feat_lab_corr_result = check_feat_lab_corr.run(dataset=abalone_train_ds)\n",
    "\n",
    "# 2. Feature–Feature Correlation Check\n",
    "#    Ensures no pair of features has correlation above 0.99.\n",
    "#    n_pairs = 0 means absolutely no correlated pairs allowed.\n",
    "check_feat_feat_corr = FeatureFeatureCorrelation().add_condition_max_number_of_pairs_above_threshold(\n",
    "    threshold = 0.99,\n",
    "    n_pairs = 0\n",
    ")\n",
    "check_feat_feat_corr_result = check_feat_feat_corr.run(dataset=abalone_train_ds)\n",
    "\n",
    "# 3. Target Distribution Check (Label Drift)\n",
    "#    Ensures the distribution of the target (\"Rings\") looks normal,\n",
    "#    and that the training and test sets come from the same population.\n",
    "#    This prevents unexpected label shifts.\n",
    "\n",
    "# Build Deepchecks dataset for test data\n",
    "abalone_test = X_test.copy()\n",
    "abalone_test[\"Rings\"] = y_test\n",
    "\n",
    "abalone_test_ds = Dataset(\n",
    "    abalone_test.drop(columns=[\"Sex_I\", \"Sex_M\"]),\n",
    "    label=\"Rings\",\n",
    "    cat_features=[]\n",
    ")\n",
    "\n",
    "# Run the target distribution drift check\n",
    "check_label_drift = LabelDrift().add_condition_drift_score_less_than(0.2)\n",
    "check_label_drift_result = check_label_drift.run(\n",
    "    train_dataset=abalone_train_ds,\n",
    "    test_dataset=abalone_test_ds\n",
    ")\n",
    "\n",
    "\n",
    "if not check_feat_lab_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature–Label correlation exceeds the acceptable threshold.\")\n",
    "\n",
    "if not check_feat_feat_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature–Feature correlation exceeds the acceptable threshold.\")\n",
    "\n",
    "if not check_label_drift_result.passed_conditions():\n",
    "    raise ValueError(\"Target variable distribution drift detected \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276e745-0d87-4887-bb0e-3ed7b55573df",
   "metadata": {},
   "source": [
    "Even though the feature–feature correlation check throws an error, the highly correlated pairs all make sense based on the biology of abalone growth. As the abalone gets older and larger, all of the weight-related measurements (whole weight, shucked weight, viscera weight, etc.) naturally increase together, so it's expected that they will be strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardize numeric features \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# 5. Define the k-NN Regressor model\n",
    "# weights=\"uniform\" -> all neighbors contribute equally\n",
    "# metric=\"minkowski\", p=2 -> Euclidean distance\n",
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors = 5,\n",
    "    weights = \"uniform\",\n",
    "    metric = \"minkowski\",\n",
    "    p=2\n",
    ")\n",
    "\n",
    "# 6. Make predictions on both train and test sets\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred = knn.predict(X_train_scaled)\n",
    "y_test_pred  = knn.predict(X_test_scaled)\n",
    "\n",
    "# 7. Evaluate performance using RMSE (Root Mean Squared Error)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse  = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(\"=== KNN Regression performance (k=5) ===\")\n",
    "print(f\"Train RMSE : {train_rmse:.4f}\")\n",
    "print(f\"Test  RMSE : {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Plot Actual vs Predicted Rings for visual inspection\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\",\n",
    "    label=\"Perfect Prediction Line\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Actual number of rings (True age proxy)\")\n",
    "plt.ylabel(\"Predicted number of rings\")\n",
    "plt.title(\"KNN model performance: actual vs predicted rings\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7238613-553d-41e3-aa09-79f1aadca9ad",
   "metadata": {},
   "source": [
    "Figure 2: Actual vs. predicted number of rings for the kNN regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca111367",
   "metadata": {},
   "source": [
    "## References: \n",
    "\n",
    "[1] Nash, W. J., Sellers, T. L., Talbot, S. R., Cawthorn, A. J., & Ford, W. B. (1994). The Population Biology of Abalone (Haliotis species) in Tasmania. I. Blacklip Abalone (H. rubra) from the North Coast and Islands of Bass Strait. Sea Fisheries Division Technical Report No. 48.\n",
    "\n",
    "[2] Dua, D., & Graff, C. (1995). Abalone Data Set. UCI Machine Learning Repository. https://archive.ics.uci.edu/dataset/1/abalone\n",
    "\n",
    "[3] Waugh, S. (1995). Extending and benchmarking Cascade-Correlation (PhD thesis). Department of Computer Science, University of Tasmania.\n",
    "\n",
    "[4] Clark, D., Schreter, Z., & Adams, A. (1996). A Quantitative Comparison of Dystal and Backpropagation. Proceedings of the Australian Conference on Neural Networks (ACNN’96)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e9a4f-a02a-45ad-99b8-ac55f0488dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "522_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
