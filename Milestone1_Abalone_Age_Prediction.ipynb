{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import altair as alt\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fc79c",
   "metadata": {},
   "source": [
    "## Title : Abalone Age Prediction based on Physical Measurements and Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ef433",
   "metadata": {},
   "source": [
    "## Summary - 1:\n",
    "\n",
    "In this project, we aimed to build a regression model using the k-Nearest Neighbours (k-NN) algorithm to predict the age of an abalone using its physical characteristics and sex. Since determining abalone age traditionally requires cutting the shell and counting rings (a destructive and time-consuming process), machine learning methods offer a non-destructive alternative for estimating age from easily measurable features. Age in this dataset is represented as Rings + 1.5, where each ring corresponds roughly to one year of growth and the additional 1.5 accounts for early development. For example, an abalone with 10 rings would be approximately 11.5 years old.\n",
    "\n",
    "Our k-NN Regressor (with $k=5$) produced an RMSE of approximately 2.2 rings on the test set, meaning the model’s predictions deviate from the true age by about 2 rings on average. The scatter plot of actual versus predicted values shows a generally increasing trend but with noticeable spread, especially among older abalones. This indicates that while k-NN captures broad growth patterns, predicting exact age remains challenging due to natural biological variability and overlapping physical features. Nevertheless, the model produces reasonable baseline performance and demonstrates that physical measurements contain meaningful information about abalone age. Further improvement could be achieved by tuning $k$ or exploring more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89617e",
   "metadata": {},
   "source": [
    "## Introduction - 2\n",
    "\n",
    "#### 2.1 Project Goal:\n",
    "Understand if physical features and sex can accurately predict the age of an abalone.\n",
    "\n",
    "#### 2.2 Background:\n",
    "Abalones are a type of marine mollusk widely harvested for food and shell products. Understanding their age is important for marine biology research, sustainable fisheries management, and conservation efforts. However, determining the age of an abalone is not straightforward. The most accurate method requires cutting the shell and counting the number of rings inside under a microscope—an approach that is destructive, labor-intensive, and not feasible at scale for monitoring wild populations.\n",
    "\n",
    "The Abalone dataset from the UCI Machine Learning Repository provides measurements of physical characteristics of abalone. These features include:\n",
    "- Categorical: Sex (M, F, I)\n",
    "- Continuous physical measurements: Length, Diameter, Height, Whole weight, Shucked weight, Viscera weight, Shell weight\n",
    "such as shell length, diameter, height, whole weight, shucked weight, viscera weight, and shell weight.\n",
    "\n",
    "The dataset contains 4,177 observations and 8 predictor variables, representing a reasonably large sample for training and evaluating regression models. The measurements reflect biological growth patterns, making them strong candidates for predicting age. In addition, these variables are non-destructive measurements that can be collected easily and consistently. Since abalone age is strongly related to its size and mass, this dataset provides an opportunity to use machine learning to predict an abalone's age from its measurable physical features.\n",
    "\n",
    "Age in this dataset is recorded using the variable Rings, where Age = Rings + 1.5 years, reflecting the biological growth process of shell formation. Because Rings is a numeric, continuous output, predicting age is naturally formulated as a regression problem. Using measurable physical features to estimate age has the potential to provide a non-destructive, scalable tool for resource management and marine science applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4c726",
   "metadata": {},
   "source": [
    "## Methods - 3\n",
    "\n",
    "#### 3.1 Model Selection:\n",
    "\n",
    "k-Nearest Neighbours (k-NN) Regressor is our chosen model to predict the age of an abalone from it's physical characteristics and sex.\n",
    "\n",
    "This model estimates the age of a new abalone by finding the k most similar abalones in the training set, where similarity is measured using Euclidean distance in the standardized feature space and averaging their observed ring counts. \n",
    "\n",
    "We selected k-NN because it is a simple, easily interpretable, and non-parametric model that does not assume linear relationships between predictors and age. Because abalone growth patterns are expected to be non-linear — with shell dimensions increasing quickly when young and more slowly with age — a flexible model such as k-NN is well suited to capture these unknown relationships between physical characteristics, sex, and age.\n",
    "\n",
    "#### 3.2 Preprocessing Steps:\n",
    "\n",
    "Prior to model fitting, all numeric features were standardized with Standard Scaler to ensure that measurements on different scales contributed equally to the distance calculations. One Hot Encoding is performed on the Sex categorical feature.\n",
    "\n",
    "Hyperparameter tuning for k will be performed in future analysis for simplicity, as noted in the Milestone 1 project instructions as well. \n",
    "\n",
    "Scoring of the model will be based on Root Mean Squared Error (RMSE), since the target variable (Rings) is a continous variable. RMSE also penalizes large errors more heavily, which is desirable for age estimations as predicting an abalone to be far older or younger than it truly is is more problematic than small deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e33b6e",
   "metadata": {},
   "source": [
    "## Discussion - 4:\n",
    "\n",
    "#### 4.1 Exploratory Data Analysis Discussion\n",
    "The exploratory data analysis reveals that most physical features, including length, diameter, height, and the different weight measurements are positively associated with the number of rings. In general, larger and heavier abalones tend to be older. However, these relationships are clearly nonlinear: growth accelerates when abalones are young and gradually tapers off, producing curved patterns in the scatterplot matrix. As measurements increase, the variability in ring counts also widens, indicating that abalones with similar sizes can still differ noticeably in age. This suggests that simple linear models may struggle to capture the underlying structure.\n",
    "\n",
    "Among the predictors, height appears to be the least informative due to its narrow range and low variability. By contrast, the various weight variables (whole weight, shucked weight, viscera weight, and shell weight) show strong and highly correlated patterns, reinforcing the need for feature scaling to prevent any single weight variable from dominating distance calculations later in modeling.\n",
    "\n",
    "The three sex categories (Male, Female, and Infant) overlap heavily across all measurements, with no visually distinct patterns separating them. At Milestone 1 of this project, for simplicity, we assume that \"sex\" alone is not a strong indicator of age. However, it is still included as a categorical feature via one-hot encoding, as we want to retain this feature for future analysis.\n",
    "\n",
    "Overall, the nonlinear growth patterns, strong correlations among weight-based predictors, and high degree of feature overlap support our choice of a k-Nearest Neighbours model. kNN is well suited to datasets where local structure matters and where the relationship between predictors and the target does not follow a simple linear form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cdd4c2",
   "metadata": {},
   "source": [
    "## Importing Dataset \n",
    "\n",
    "#### Steps \n",
    "1. Prepare data validation Schema using Pandera\n",
    "2. Load Data via URL \n",
    "3. Apply the Pandera Schema to validate the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea0c26",
   "metadata": {},
   "source": [
    "##### Checking if packages are imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215590fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera.pandas as pa\n",
    "import deepchecks\n",
    "import pointblank as pb\n",
    "\n",
    "# Checking if packages are imported correctly\n",
    "print(\"Deepchecks:\", deepchecks.__version__)\n",
    "print(\"Pointblank:\", pb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234613a",
   "metadata": {},
   "source": [
    "##### Setting up Data Checking Schema\n",
    "\n",
    "Data Type of choice is selected from the original dataset source.\n",
    "\n",
    "We will use Pandera to check the followings: \n",
    "\n",
    "    1. Correct data file format\n",
    "\n",
    "    2. Correct column names\n",
    "\n",
    "    3. No empty observations\n",
    "\n",
    "    4. Missingness not beyond expected threshold\n",
    "\n",
    "    5. Correct data types in each column\n",
    "\n",
    "    6. No duplicate observations\n",
    "\n",
    "    7. No outlier or anomalous values\n",
    "\n",
    "    8. Correct category levels (i.e., no string mismatches or single values)\n",
    "\n",
    "We will use Deepcheck to check the followings: \n",
    "\n",
    "    9. Target/response variable follows expected distribution\n",
    "\n",
    "    10. No anomalous correlations between target/response variable and features/explanatory variables\n",
    "    \n",
    "    11. No anomalous correlations between features/explanatory variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4baecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import Column, Check, DataFrameSchema\n",
    "\n",
    "# Allowed categories for Sex\n",
    "SEX_CATEGORIES = [\"M\", \"F\", \"I\"]\n",
    "\n",
    "abalone_schema = DataFrameSchema(\n",
    "    {\n",
    "        \"Sex\": Column(\n",
    "            str,\n",
    "            Check.isin(SEX_CATEGORIES),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Length\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Diameter\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Height\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Whole_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Shucked_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Viscera_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Shell_weight\": Column(\n",
    "            float,\n",
    "            Check.ge(0.0),\n",
    "            nullable=False\n",
    "        ),\n",
    "        \"Rings\": Column(\n",
    "            int,\n",
    "            Check.between(1, 30),\n",
    "            nullable=False\n",
    "        )\n",
    "    },\n",
    "    checks=[\n",
    "        Check(lambda df: ~df.duplicated().any(), error=\"Duplicate rows found.\"),\n",
    "        Check(lambda df: ~(df.isna().all(axis=1)).any(), error=\"Empty rows found.\"),\n",
    "        Check(lambda df: (df.isna().mean() <= 0.05).all(),\n",
    "              error=\"Missingness exceeds 5% threshold.\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f424bdc",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac361e10-ddcf-4348-bdbd-8a56c917c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "\n",
    "column_names = [\n",
    "    \"Sex\", \"Length\", \"Diameter\", \"Height\",\n",
    "    \"Whole_weight\", \"Shucked_weight\",\n",
    "    \"Viscera_weight\", \"Shell_weight\", \"Rings\"\n",
    "]\n",
    "\n",
    "#This ensures our data is freshly loaded everytime :) \n",
    "#Creating a function here for the loading process: \n",
    "\n",
    "def load_and_validate_abalone() -> pd.DataFrame:\n",
    "    #1) Loading data \n",
    "    abalone_raw = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "    #2) validation with pandera\n",
    "    abalone_validated = abalone_schema.validate(abalone_raw, lazy=True)\n",
    "\n",
    "    return abalone_validated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10edb4",
   "metadata": {},
   "source": [
    "#### Validation with Pandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54164922",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = load_and_validate_abalone()\n",
    "\n",
    "#Saving the validated dataset\n",
    "abalone.to_csv(\"data/abalone_validated.csv\", index=False)\n",
    "\n",
    "# Peeking the dataframe\n",
    "abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527329d1",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "We will be perform a pairwise plot below to assess feature correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6e911-5142-41d0-b35e-f8e53b224fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding column: Sex for cleaner display of graphs\n",
    "new_column_names = [\"Length\", \"Diameter\", \"Height\",\n",
    "    \"Whole_weight\", \"Shucked_weight\",\n",
    "    \"Viscera_weight\", \"Shell_weight\", \"Rings\"\n",
    "]\n",
    "\n",
    "# Plot all variables against one another for EDA\n",
    "chart = alt.Chart(abalone,width=150, height=100).mark_point().encode(\n",
    "  alt.X(alt.repeat('row'), type='quantitative'),\n",
    "  alt.Y(alt.repeat('column'), type='quantitative'),\n",
    "    color='Sex:N'\n",
    ").repeat(column = new_column_names, row = new_column_names\n",
    ").properties(title = \"Scatterplot matrix\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1008ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. One-hot encode the Sex categorical variable\n",
    "# get_dummies() converts categories (M, F, I) -> columns Sex_F and Sex_M\n",
    "# drop_first=True avoids creating redundant dummy columns\n",
    "\n",
    "abalone_converted = pd.get_dummies(abalone, columns=[\"Sex\"], drop_first=True)\n",
    "\n",
    "# 2. Split predictors (X) and target variable (y)\n",
    "# \"Rings\" is the target we want to predict (continuous -> regression)\n",
    "\n",
    "X = abalone_converted.drop(\"Rings\", axis=1)\n",
    "y = abalone_converted[\"Rings\"]\n",
    "abalone_converted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ada80d-5a4f-4293-81ce-0ab3450b44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train-test split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ed45a",
   "metadata": {},
   "source": [
    "#### Validations with Deepcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c5f20-8016-4c08-87ba-af826765a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate training data for anomalous correlations between target/response variable \n",
    "# and features/explanatory variables, \n",
    "# as well as anomalous correlations between features/explanatory variables\n",
    "# Do these on training data as part of EDA\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureFeatureCorrelation, MultivariateDrift, LabelDrift\n",
    "from deepchecks.tabular import Dataset\n",
    "\n",
    "# Combine X_train and y_train to form training dataset\n",
    "abalone_train = X_train.copy()\n",
    "abalone_train[\"Rings\"] = y_train\n",
    "\n",
    "\n",
    "# Setting up Dataset object for Deepcheck\n",
    "abalone_train_ds = Dataset(\n",
    "    abalone_train.drop(columns=[\"Sex_I\", \"Sex_M\"]), \n",
    "    label=\"Rings\",\n",
    "    cat_features=[]\n",
    ")\n",
    "\n",
    "# 1. Feature–Label Correlation Check\n",
    "#    Ensures no single feature is too predictive of the target.\n",
    "#    PPS (predictive power score) must remain < 0.9.\n",
    "check_feat_lab_corr = FeatureLabelCorrelation().add_condition_feature_pps_less_than(0.9)\n",
    "check_feat_lab_corr_result = check_feat_lab_corr.run(dataset=abalone_train_ds)\n",
    "\n",
    "# 2. Feature–Feature Correlation Check\n",
    "#    Ensures no pair of features has correlation above 0.99.\n",
    "#    n_pairs = 0 means absolutely no correlated pairs allowed.\n",
    "check_feat_feat_corr = FeatureFeatureCorrelation().add_condition_max_number_of_pairs_above_threshold(\n",
    "    threshold = 0.99,\n",
    "    n_pairs = 0\n",
    ")\n",
    "check_feat_feat_corr_result = check_feat_feat_corr.run(dataset=abalone_train_ds)\n",
    "\n",
    "# 3. Target Distribution Check (Label Drift)\n",
    "#    Ensures the distribution of the target (\"Rings\") looks normal,\n",
    "#    and that the training and test sets come from the same population.\n",
    "#    This prevents unexpected label shifts.\n",
    "\n",
    "# Build Deepchecks dataset for test data\n",
    "abalone_test = X_test.copy()\n",
    "abalone_test[\"Rings\"] = y_test\n",
    "\n",
    "abalone_test_ds = Dataset(\n",
    "    abalone_test.drop(columns=[\"Sex_I\", \"Sex_M\"]),\n",
    "    label=\"Rings\",\n",
    "    cat_features=[]\n",
    ")\n",
    "\n",
    "# Run the target distribution drift check\n",
    "check_label_drift = LabelDrift().add_condition_drift_score_less_than(0.2)\n",
    "check_label_drift_result = check_label_drift.run(\n",
    "    train_dataset=abalone_train_ds,\n",
    "    test_dataset=abalone_test_ds\n",
    ")\n",
    "\n",
    "\n",
    "if not check_feat_lab_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature–Label correlation exceeds the acceptable threshold.\")\n",
    "\n",
    "if not check_feat_feat_corr_result.passed_conditions():\n",
    "    raise ValueError(\"Feature–Feature correlation exceeds the acceptable threshold.\")\n",
    "\n",
    "if not check_label_drift_result.passed_conditions():\n",
    "    raise ValueError(\"Target variable distribution drift detected \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276e745-0d87-4887-bb0e-3ed7b55573df",
   "metadata": {},
   "source": [
    "Even though the feature–feature correlation check throws an error, the highly correlated pairs all make sense based on the biology of abalone growth. As the abalone gets older and larger, all of the weight-related measurements (whole weight, shucked weight, viscera weight, etc.) naturally increase together, so it's expected that they will be strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardize numeric features \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# 5. Define the k-NN Regressor model\n",
    "# weights=\"uniform\" -> all neighbors contribute equally\n",
    "# metric=\"minkowski\", p=2 -> Euclidean distance\n",
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors = 5,\n",
    "    weights = \"uniform\",\n",
    "    metric = \"minkowski\",\n",
    "    p=2\n",
    ")\n",
    "\n",
    "# 6. Make predictions on both train and test sets\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_train_pred = knn.predict(X_train_scaled)\n",
    "y_test_pred  = knn.predict(X_test_scaled)\n",
    "\n",
    "# 7. Evaluate performance using RMSE (Root Mean Squared Error)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse  = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(\"=== KNN Regression performance (k=5) ===\")\n",
    "print(f\"Train RMSE : {train_rmse:.4f}\")\n",
    "print(f\"Test  RMSE : {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Plot Actual vs Predicted Rings for visual inspection\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Actual Rings\")\n",
    "plt.ylabel(\"Predicted Rings\")\n",
    "plt.title(\"KNN Regression: Actual vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca111367",
   "metadata": {},
   "source": [
    "## References: \n",
    "\n",
    "Dua, D., & Graff, C. (1995). Abalone Data Set. UCI Machine Learning Repository. https://archive.ics.uci.edu/dataset/1/abalone\n",
    "\n",
    "Nash, W. J., Sellers, T. L., Talbot, S. R., Cawthorn, A. J., & Ford, W. B. (1994). The Population Biology of Abalone (Haliotis species) in Tasmania. I. Blacklip Abalone (H. rubra) from the North Coast and Islands of Bass Strait. Sea Fisheries Division Technical Report No. 48.\n",
    "\n",
    "Waugh, S. (1995). Extending and benchmarking Cascade-Correlation (PhD thesis). Department of Computer Science, University of Tasmania.\n",
    "\n",
    "Clark, D., Schreter, Z., & Adams, A. (1996). A Quantitative Comparison of Dystal and Backpropagation. Proceedings of the Australian Conference on Neural Networks (ACNN’96)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsci_522_lab_env]",
   "language": "python",
   "name": "conda-env-dsci_522_lab_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
